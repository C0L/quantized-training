{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_dir):\n",
    "    data = {}\n",
    "    for prefix in ['activations', 'errors', 'weights', 'gradients']:\n",
    "        file_path = os.path.join(data_dir, f'{prefix}.pkl')\n",
    "\n",
    "        if os.path.exists(file_path):\n",
    "            with open(file_path, 'rb') as file:\n",
    "                data[prefix] = pickle.load(file)\n",
    "                print(f\"Loaded {prefix} successfully.\")\n",
    "        else:\n",
    "            print(f\"File for {prefix} not found.\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the activation, weights, and activations gradients into a single array\n",
    "# train_data = read_data('data/squad_train/step_1000')\n",
    "train_data = read_data('data/sst2_train/step_500')\n",
    "activation_array = np.concatenate([tensor.flatten() for tensor in train_data['activations'].values()])\n",
    "weight_array = np.concatenate([tensor.flatten() for tensor in train_data['weights'].values()])\n",
    "error_array = np.concatenate([tensor.flatten() for tensor in train_data['errors'].values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(ax, data, label, xlabel=False):\n",
    "    exp = np.floor(np.log2(np.abs(data[data != 0]))).astype(int)\n",
    "    exp = np.clip(exp, -126, 127)\n",
    "    bins = np.linspace(exp.min(), exp.max(), exp.max() - exp.min() + 1)\n",
    "    counts, bins, patches = ax.hist(exp, bins=bins, density=True, edgecolor='black')\n",
    "\n",
    "    ax.axvspan(-12, 12, color='grey', alpha=0.3)\n",
    "    ax.axvspan(-9, 8, color='grey', alpha=0.3)\n",
    "\n",
    "    ax.tick_params(axis='both', which='major', labelsize=20)\n",
    "    ax.xaxis.set_major_formatter(FormatStrFormatter('%0.0f'))\n",
    "    ax.set_xlim(xmin=-60, xmax=15)\n",
    "    ax.set_yticks(ax.get_yticks()[1:-1])  # Exclude first and last y-tick to prevent overlap\n",
    "    ax.text(-58, ax.get_ylim()[1] * 0.88, label, fontsize=20)  # Label position\n",
    "\n",
    "    plt.setp(ax.get_xticklabels(), visible=xlabel)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8), dpi=100)\n",
    "gs = gridspec.GridSpec(3, 1, height_ratios=[1, 1, 1], hspace=0)\n",
    "labels = [\"activation\", \"weight\", \"gradient\"]\n",
    "\n",
    "for i, array in enumerate([activation_array, weight_array, error_array]):\n",
    "    ax = plt.subplot(gs[i])\n",
    "    if i == 2:\n",
    "        array = array * 1024\n",
    "    plot_distribution(ax, array, label=labels[i], xlabel=(i == 2))\n",
    "\n",
    "    if i == 1:\n",
    "        ax.set_ylabel(\"Density\", fontsize=20, labelpad=10)\n",
    "    if i == 2:\n",
    "        ax.set_xlabel(\"Exponent Value\", fontsize=20)\n",
    "\n",
    "plt.subplots_adjust(left=0.15, top=0.90, bottom=0.10, right=0.95)\n",
    "plt.savefig('mobilebert_tensors.png', transparent=True, bbox_inches='tight', pad_inches=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_layer_and_tensor_name(key):\n",
    "    # Using regular expression to extract the layer index and tensor name\n",
    "    match = re.search(r\"mobilebert.encoder.layer.(\\d+).(.+)\", key)\n",
    "    if match:\n",
    "        layer_index = int(match.group(1))\n",
    "        tensor_name = match.group(2)\n",
    "        return layer_index, tensor_name\n",
    "    return None, None\n",
    "\n",
    "def concatenate_tensors(tensor_dict):\n",
    "    concatenated = {}\n",
    "    for key, value in tensor_dict.items():\n",
    "        layer_index, tensor_name = extract_layer_and_tensor_name(key)\n",
    "        if tensor_name:\n",
    "            if tensor_name not in concatenated:\n",
    "                concatenated[tensor_name] = []\n",
    "            concatenated[tensor_name].append(value)\n",
    "\n",
    "    # Concatenating tensors for each name\n",
    "    for tensor_name in concatenated:\n",
    "        concatenated[tensor_name] = np.concatenate(concatenated[tensor_name])\n",
    "\n",
    "    return concatenated\n",
    "\n",
    "inference_data = read_data('data/squad_inference/step_0')\n",
    "activation_concat = concatenate_tensors(inference_data['activations'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize plot settings\n",
    "plt.clf()\n",
    "plt.figure(figsize=(10, 8), dpi=100)\n",
    "\n",
    "# Constants for labels\n",
    "fontsize_label, fontsize_ticks = 20, 16\n",
    "\n",
    "# Plotting each activation distribution\n",
    "def plot_dist(inputs, label, linewidth=2, num_points=500):\n",
    "    exp = np.floor(np.log2(np.abs(inputs[inputs != 0]))).astype(int)\n",
    "\n",
    "    num_bins = exp.max() - exp.min()\n",
    "    hist, bin_edges = np.histogram(exp, bins=num_bins, density=True)\n",
    "    bin_edges = bin_edges[1:]\n",
    "\n",
    "    x = np.linspace(bin_edges.min(), bin_edges.max(), num_points)\n",
    "    f = interp1d(bin_edges, hist, 'quadratic')\n",
    "\n",
    "    plt.plot(x, f(x), label=label, linewidth=linewidth)\n",
    "\n",
    "for k, v in activation_concat.items():\n",
    "    plot_dist(v, k, linewidth=3)\n",
    "\n",
    "# Configure plot appearance\n",
    "plt.xlim(left=-15, right=15)\n",
    "plt.xlabel('Exponent Value', fontsize=fontsize_label)\n",
    "plt.ylabel('Density', fontsize=fontsize_label)\n",
    "plt.xticks(fontsize=fontsize_ticks)\n",
    "plt.yticks(fontsize=fontsize_ticks)\n",
    "\n",
    "# Adding shaded regions to the plot\n",
    "shaded_regions = [(-2, 2), (-4, 4), (-6, 6), (-8, 8)]\n",
    "shaded_alpha = [0.3, 0.51, 0.657, 0.759]\n",
    "for region, alpha in zip(shaded_regions, shaded_alpha):\n",
    "    plt.axvspan(region[0], region[1], color='grey', alpha=0.3)\n",
    "\n",
    "# Creating and adding legend handles\n",
    "labels = ['1 bit', '2 bits', '3 bits', '4 bits']\n",
    "handles = [mpatches.Patch(color='grey', alpha=a, label=l) for a, l in zip(shaded_alpha, labels)]\n",
    "plt.legend(handles=handles, loc='upper left', fontsize=fontsize_label)\n",
    "\n",
    "# Save the plot to a file\n",
    "plt.savefig('mobilebert_activation.png', bbox_inches='tight', transparent=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "hist1 = torch.load(\"error_pre_process.pt\").cpu()\n",
    "hist2 = torch.roll(hist1, 8)\n",
    "\n",
    "non_empty_bins1 = torch.nonzero(hist1).flatten()\n",
    "non_empty_bins2 = torch.nonzero(hist2).flatten()\n",
    "\n",
    "first_non_zero = min(non_empty_bins1[0], non_empty_bins2[0])\n",
    "last_non_zero = max(non_empty_bins1[-1], non_empty_bins2[-1])\n",
    "\n",
    "hist1 = hist1[first_non_zero:last_non_zero + 1]\n",
    "hist2 = hist2[first_non_zero:last_non_zero + 1]\n",
    "\n",
    "bins = torch.linspace(-126, 127, 255)\n",
    "bins = bins[first_non_zero:last_non_zero + 2]\n",
    "bar_width = (bins[1] - bins[0]) * 0.4\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(bins[:-1] - bar_width/2, hist1, width=bar_width, label='Without loss scaling')\n",
    "plt.bar(bins[:-1] + bar_width/2, hist2, width=bar_width, label='With loss scaling')\n",
    "\n",
    "plt.fill_betweenx([0, max(max(hist1), max(hist2))], -12, 12, color='gray', alpha=0.3)\n",
    "\n",
    "plt.title('Activation Distribution')\n",
    "plt.xlabel('Exponent Value')\n",
    "plt.ylabel('Count')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"loss_scaling\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
