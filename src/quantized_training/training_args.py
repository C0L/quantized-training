import argparse
from dataclasses import dataclass, field
from typing import Optional, Tuple, List

from .utils import SLURM_ARGS

__all__ = [
    "QuantizedTrainingArguments",
    "add_training_args",
]


class DelayedScaling(argparse.Action):
    def __call__(self, parser, namespace, values, option_string=None):
        # Default values for qscheme, quant_max, and amax_history_len
        defaults = ["per_tensor", 64.0, 50]

        # Update defaults with any provided values
        for i, value in enumerate(values):
            defaults[i] = value
        defaults = (defaults[0], float(defaults[1]), int(defaults[2]))

        setattr(namespace, self.dest, defaults)


@dataclass
class QuantizedTrainingArguments:
    project: Optional[str] = field(
        default=None,
        metadata={"help": "The name of the project where the new run will be sent."}
    )
    run_name: Optional[str] = field(
        default=None,
        metadata={
            "help": "A short display name for this run, which is this run will be identified in the UI."
        }
    )
    run_id: Optional[str] = field(
        default=None,
        metadata={"help": "A unique ID for a wandb run, used for resuming."}
    )
    sweep_config: Optional[str] = field(
        default=None,
        metadata={"help": "Path to JSON file that stores W&B sweep configuration."}
    )
    sweep_id: Optional[str] = field(
        default=None,
        metadata={
            "help": "The unique identifier for a sweep generated by W&B CLI or Python SDK."
        }
    )
    max_trials: Optional[int] = field(
        default=None,
        metadata={"help": "The number of sweep config trials to try."}
    )
    log_level: str = field(
        default="INFO",
        metadata={
            "help": "Set the logging level",
            "choices": ["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"]
        }
    )
    log_file: Optional[str] = field(
        default=None,
        metadata={
            "help": "Set the logging file. If not specified, the log will be printed to stdout.",
            "nargs": '?',
            "const": ""
        }
    )
    # =============================================================================
    # ================= GENERAL TRAINING ARGUMENTS SECTION ========================
    # =============================================================================
    gpu: Optional[int] = field(default=None, metadata={"help": "GPU to use."})
    do_train: bool = field(
        default=False, metadata={"help": "Whether to run training"}
    )
    sgd: bool = field(
        default=False, metadata={"help": "Whether to use SGD optimizer."}
    )
    warmup_ratio: float = field(
        default=0.0, metadata={"help": "Ratio of warmup steps in the lr scheduler."}
    )
    bf16: bool = field(
        default=False,
        metadata={
            "help": "Whether to use bf16 (mixed) precision instead of 32-bit float."
        }
    )
    num_hidden_layers: Optional[int] = field(
        default=None,
        metadata={"help": "Number of Tranformer encoder layers to use."}
    )
    lora_rank: int = field(
        default=0,
        metadata={"help": "The dimension of the low-rank matrices."}
    )
    lora_alpha: int = field(
        default=8,
        metadata={"help": "The scaling factor for the low-rank matrices."}
    )
    target_modules: List[str] = field(
        default="query,value",
        metadata={
            "help": "The modules (for example, attention blocks) to apply the LoRA update matrices.",
            "type": lambda x: x.split(','),
        }
    )
    # =============================================================================
    # ================= QUANTIZATION ARGUMENTS SECTION ============================
    # =============================================================================
    dtype: str = field(
        default="posit8_1",
        metadata={
            "help": "Quantization data type to use. Choose between posit(nbits)_(es), FP8_(E4M3|E5M2), and FP8(.MIXED)."
        }
    )
    quantize_weights: bool = field(
        default=False,
        metadata={"help": "Whether to quantize model weights."}
    )
    quantize_fwd: Optional[str] = field(
        default=None,
        metadata={
            "help": "Whether to quantize activations. Choose from gemm, act, norm, scaling, and residual.",
            "nargs": '?',
            "const": 'gemm'
        }
    )
    quantize_bwd: Optional[str] = field(
        default=None,
        metadata={
            "help": "Whether to quantize activation gradients. Choose from gemm, act, norm, scaling, and residual.",
            "nargs": '?',
            "const": 'gemm'
        }
    )
    scaling_fwd: Tuple = field(
        default=(None, None, 0),
        metadata={
            "help": "Specify quantization scheme and parameters. Defaults to no scaling.",
            "action": DelayedScaling,
        }
    )
    scaling_bwd: Tuple = field(
        default=(None, None, 0),
        metadata={
            "help": "Specify quantization scheme and parameters. Defaults to no scaling.",
            "action": DelayedScaling,
        }
    )
    op_fusion: Optional[str] = field(
        default=None,
        metadata={
            "help": "Fuse operation with previous GEMM to reduce quantization error.",
            "type": lambda x: x.split(','),
        }
    )
    posit_exp: bool = field(
        default=False,
        metadata={
            "help": "Whether to use posit approximated exponential function in softmax.",
        }
    )
    posit_exp_shifted: bool = field(
        default=False,
        metadata={
            "help": "Whether to use shifted posit approximated exponential function in softmax.",
        }
    )
    posit_reciprocal: bool = field(
        default=False,
        metadata={
            "help": "Whether to use posit approximated reciprocal function in softmax.",
        }
    )
    record_histogram: bool = field(
        default=False,
        metadata={
            "help": "Whether to store and plot the histogram of tensor value.",
        }
    )


# FIXME: this function should be deprecated
def add_training_args(parser=None):
    if parser is None:
        parser = argparse.ArgumentParser(
            description="Run quantized inference or training.")
    # =============================================================================
    # ================= W&B RELATED ARGUMENTS SECTION =============================
    # =============================================================================
    parser.add_argument(
        '--project',
        default=None,
        help='The name of the project where the new run will be sent.'
    )
    parser.add_argument(
        '--run_name',
        default=None,
        help='A short display name for this run, which is this run will be identified in the UI.'
    )
    parser.add_argument(
        '--run_id',
        default=None,
        help='A unique ID for a wandb run, used for resuming.'
    )
    parser.add_argument(
        '--sweep_config',
        default=None,
        help='Path to JSON file that stores W&B sweep configuration.'
    )
    parser.add_argument(
        '--sweep_id',
        default=None,
        help='The unique identifier for a sweep generated by W&B CLI or Python SDK.'
    )
    parser.add_argument(
        "--max_trials",
        type=int,
        default=None,
        help="The number of sweep config trials to try."
    )
    # =============================================================================
    # ================= LOGGING ARGUMENTS SECTION =================================
    # =============================================================================
    parser.add_argument(
        "--log_level",
        choices=["DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"],
        default="INFO",
        help="Set the logging level"
    )
    parser.add_argument(
        "--log_file",
        nargs='?',
        const="",
        default=None,
        help="Set the logging file. If not specified, the log will be printed to stdout."
    )
    # =============================================================================
    # ================= GENERAL TRAINING ARGUMENTS SECTION ========================
    # =============================================================================
    parser.add_argument("--gpu", type=int, default=None, help="GPU to use.")
    parser.add_argument(
        "--do_train", action="store_true", help="Whether to run training"
    )
    parser.add_argument(
        "--sgd", action="store_true", help="Whether to use SGD optimizer."
    )
    parser.add_argument(
        "--warmup_ratio", type=float, default=0.0, help="Ratio of warmup steps in the lr scheduler."
    )
    parser.add_argument(
        "--bf16",
        action="store_true",
        help="Whether to use bf16 (mixed) precision instead of 32-bit float."
    )
    parser.add_argument(
        "--num_hidden_layers",
        type=int,
        default=None,
        help="Number of Tranformer encoder layers to use."
    )
    parser.add_argument(
        "--lora_rank",
        type=int,
        default=0,
        help="The dimension of the low-rank matrices."
    )
    parser.add_argument(
        "--lora_alpha",
        type=int,
        default=8,
        help="The scaling factor for the low-rank matrices."
    )
    parser.add_argument(
        "--target_modules",
        type=lambda x: x.split(','),
        default="query,value",
        help="The modules (for example, attention blocks) to apply the LoRA update matrices."
    )
    # =============================================================================
    # ================= QUANTIZATION ARGUMENTS SECTION ============================
    # =============================================================================
    parser.add_argument(
        "--dtype",
        default="posit8_1",
        help=(
            "Quantization data type to use. Choose between posit(nbits)_(es), FP8_(E4M3|E5M2), and FP8(.MIXED)."
        ),
    )
    parser.add_argument(
        "--quantize_weights",
        action="store_true",
        help="Whether to quantize model weights.",
    )
    parser.add_argument(
        "--quantize_fwd",
        nargs='?',
        const='gemm',
        default=None,
        help=(
            "Whether to quantize activations. Choose from gemm, act, norm, scaling, and residual."
        ),
    )
    parser.add_argument(
        "--quantize_bwd",
        nargs='?',
        const='gemm',
        default=None,
        help=(
            "Whether to quantize activation gradients. Choose from gemm, act, norm, scaling, and residual."
        ),
    )
    parser.add_argument(
        "--scaling_fwd",
        nargs='*',
        action=DelayedScaling,
        default=(None, None, 0),
        help=(
            "Specify quantization scheme and parameters. Specify in order of "
            "qscheme, quant_max, and amax_history_len. Defaults to no scaling."
        ),
    )
    parser.add_argument(
        "--scaling_bwd",
        nargs='*',
        action=DelayedScaling,
        default=(None, None, 0),
        help=(
            "Specify quantization scheme and parameters. Specify in order of "
            "qscheme, quant_max, and amax_history_len. Defaults to no scaling."
        ),
    )
    parser.add_argument(
        "--op_fusion",
        type=lambda x: x.split(','),
        default=None,
        help="Fuse operation with previous GEMM to reduce quantization error.",
    )
    parser.add_argument(
        "--posit_exp",
        action="store_true",
        help="Whether to use posit approximated exponential function in softmax."
    )
    parser.add_argument(
        "--posit_exp_shifted",
        action="store_true",
        help="Whether to use shifted posit approximated exponential function in softmax."
    )
    parser.add_argument(
        "--posit_reciprocal",
        action="store_true",
        help="Whether to use posit approximated reciprocal function in softmax."
    )
    parser.add_argument(
        "--record_histogram",
        action="store_true",
        help="Whether to store and plot the histogram of tensor value.",
    )
    # =============================================================================
    # ================= SLURM RELATED ARGUMENTS SECTION ===========================
    # =============================================================================
    subparsers = parser.add_subparsers(help='sub-command help', dest='action')
    parser_slurm = subparsers.add_parser("slurm", help="slurm command help")
    for k, v in SLURM_ARGS.items():
        parser_slurm.add_argument("--" + k, **v)
    parser_bash = subparsers.add_parser("bash", help="bash command help")
    return parser
